# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16JhW-eqgazak7JxWNS1Ia9ai6ujnFSgz
"""

#import libraries#
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#import dataset#
credit_card = pd.read_csv('/content/creditcard.csv')
credit_card.head()

#explanatory data analysis#
rows, columns = credit_card.shape
print(f"Number of Rows: {rows}")
print(f"Number of Columns: {columns}")

credit_card.tail()

credit_card.info()

credit_card.isnull().sum()

credit_card.duplicated().sum()

credit_card.duplicated().any()

credit_card.shape

#remove duplicates#
credit_card_new = credit_card.drop_duplicates()
credit_card_new.shape

print(f"Duplicate Transaction:",284807 - 283726)

credit_card_new.head()

credit_card_new.columns

credit_card_new.duplicated().any()

credit_card_new.shape

credit_card_new['Class'].value_counts()

credit_card_new['Class'].value_counts().plot(kind = 'bar')

credit_card_new['Class'].value_counts().plot(kind = 'pie')

fraud,legitimate = credit_card_new['Class'].value_counts()

print(f"Fraud Transaction(0): {fraud}")
print(f"Legitimate Transaction (1): {legitimate}")
print(f"This is imbalance data")

fraud = credit_card_new[credit_card_new['Class']==0]
legitimate = credit_card_new[credit_card_new['Class']==1]

#statistics data#
credit_card_new.describe()

"""Y - dependent variable;
X - independent variable
"""

#class is our target column#
X = credit_card_new.drop('Class', axis=1)
Y = credit_card_new['Class']

"""Handle duplication"""

X.shape

Y.shape

# !pip install imblearn

from imblearn.over_sampling import SMOTE

# specify random state for reproducibility
smote = SMOTE(random_state=42)
x_smote, y_smote = smote.fit_resample(X, Y)

x_smote.shape

y_smote.value_counts()

from collections import Counter

print('Original dataset shape', Counter(Y))
print('Resample dataset shape', Counter(y_smote))

#data visualisation#
fraud_data = credit_card_new[credit_card_new['Class'] == 0]
legitimate_data = credit_card_new[credit_card_new['Class'] == 1]

fraud_data['Amount'].plot(kind = 'hist')

legitimate_data['Amount'].plot(kind = 'hist')

fraud_data['Amount'].plot(kind = 'box')

legitimate_data['Amount'].plot(kind = 'box')

corr_imbalanced = credit_card.corr()
corr_imbalanced

corr_imbalanced = credit_card.corr()
plt.figure(figsize=(8,6))
sns.heatmap(corr_imbalanced, annot=False, cmap="plasma", linewidth=0.5)
plt.title("Correlation Matrix for Imbalanced Data")
plt.show()

#correlation matrix in imbalanced data#
corr_balanced = x_smote.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_balanced, annot=False, cmap="plasma", linewidth=0.5)
plt.title("Correlation Matrix for Balanced Data")
plt.show()

custom_palette = sns.color_palette(["blue", "gold"])
plt.figure(figsize=(8, 6))
sns.countplot(x="Class", data=credit_card_new, palette=custom_palette)
plt.title("Class Distribution")
plt.show()

custom_palette = sns.color_palette(["blue", "gold"])
plt.figure(figsize=(8, 6))
sns.countplot(x=y_smote, palette=custom_palette)
plt.title("Distribution of Classes After Resampling (SMOTE)")
plt.xlabel("Class (0: Fraud, 1: Legitimate)")
plt.ylabel("Count")
plt.show()

#split dataset for test and train#
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(x_smote, y_smote, test_size=0.20, random_state=42)

#model building#
#models will be based on logistic regression#
# build logistic regression model
from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(random_state=42)
logistic_model.fit(X_train, Y_train)

#Generating predictions 1.predit transactions as fraudulent or genuine by giving random sample#

Y_pred_logistic = logistic_model.predict(X_test)

"""Classification performance metrics |Accuracy: measures proportion of correctly predicted instances out of total instances |Precision: measure of a classifier's exactness. low precision indicates high number of false positives |Recall: measure of classifier's completeness. low recall indicates high number of false negatives |F1-score: weighted average of precision and recall |ROC-AUC: AUROC represents likelihood of model distinguishing observations from two classes |Confusion matrix: table showing correct predictions and types of incorrect predictions"""

#Classification report
from sklearn.metrics import confusion_matrix, classification_report
classification_report_logistic = classification_report(Y_test, Y_pred_logistic)
print(classification_report_logistic)

#confusion matrix#
confusion_matrix_logistic = confusion_matrix(Y_test, Y_pred_logistic)
confusion_matrix_logistic

confusion_matrix_df = pd.DataFrame(confusion_matrix_logistic,
                                   columns=["Predicted Negative (0)", "Predicted Positive (1)"],
                                   index=["Actual Negative (0)", "Actual Positive (1)"])
confusion_matrix_df

plt.figure(figsize=(7, 5))
sns.heatmap(confusion_matrix_df, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

#customised predictions#
transaction_data = pd.DataFrame({
    'Time': [16],
    'V1': [1.322707269],
    'V2': [-0.174040833],
    'V3': [0.434555031],
    'V4': [0.576037652],
    'V5': [-0.836758046],
    'V6': [-0.831083411],
    'V7': [-0.264904961],
    'V8': [-0.220981943],
    'V9': [-1.071424618],
    'V10': [0.868558548],
    'V11': [-0.64150629],
    'V12': [-0.111315775],
    'V13': [0.36148541],
    'V14': [0.171945122],
    'V15': [0.782166532],
    'V16': [-1.35587073],
    'V17': [-0.216935153],
    'V18': [1.271765385],
    'V19': [-1.240621935],
    'V20': [-0.522950941],
    'V21': [-0.284375572],
    'V22': [-0.323357411],
    'V23': [-0.037709905],
    'V24': [0.347150939],
    'V25': [0.559639137],
    'V26': [-0.280158166],
    'V27': [0.042335258],
    'V28': [0.0288223],
    'Amount': [0],
    'Class': [0]
})

transaction_data

new_predictions = logistic_model.predict(transaction_data.drop(columns=['Class']))

if new_predictions[0] == 1:
    print("Time: 16\nPredict: Fraudulent Transaction")
else:
    print("Time: 16\nPredict: Genuine Transaction")

#generating 28 random transactions & predict transactions#
#define minimum and maximum 'time' values from training data#
min_time = transaction_data['Time'].min()
max_time = transaction_data['Time'].max()

random_transactions = []

#generate 28 random transactions#
for _ in range(28):
    new_transaction = {
        'Time': np.random.uniform(min_time, max_time),
        'Amount': np.random.uniform(0, 500),
        'V1': np.random.uniform(-2, 2),
        'V2': np.random.uniform(-2, 2),
        'V3': np.random.uniform(-2, 2),
        'V4': np.random.uniform(-2, 2),
        'V5': np.random.uniform(-2, 2),
        'V6': np.random.uniform(-2, 2),
        'V7': np.random.uniform(-2, 2),
        'V8': np.random.uniform(-2, 2),
        'V9': np.random.uniform(-2, 2),
        'V10': np.random.uniform(-2, 2),
        'V11': np.random.uniform(-2, 2),
        'V12': np.random.uniform(-2, 2),
        'V13': np.random.uniform(-2, 2),
        'V14': np.random.uniform(-2, 2),
        'V15': np.random.uniform(-2, 2),
        'V16': np.random.uniform(-2, 2),
        'V17': np.random.uniform(-2, 2),
        'V18': np.random.uniform(-2, 2),
        'V19': np.random.uniform(-2, 2),
        'V20': np.random.uniform(-2, 2),
        'V21': np.random.uniform(-2, 2),
        'V22': np.random.uniform(-2, 2),
        'V23': np.random.uniform(-2, 2),
        'V24': np.random.uniform(-2, 2),
        'V25': np.random.uniform(-2, 2),
        'V26': np.random.uniform(-2, 2),
        'V27': np.random.uniform(-2, 2),
        'V28': np.random.uniform(-2, 2),
    }
    random_transactions.append(new_transaction)


random_data = pd.DataFrame(random_transactions, columns=X_train.columns)
random_data

random_predictions = logistic_model.predict(random_data)

for i, prediction in enumerate(random_predictions):
    if prediction == 0:
        print(f"Transaction {i + 1}: Genuine Transaction")
    else:
        print(f"Transaction {i + 1}: Fraudulent Transaction")

#ROC_AUC curve#
from sklearn.metrics import roc_curve, auc
y_scores = logistic_model.predict_proba(X_test)[:, 1]
y_scores

logistic_model.predict_proba(X_test)

fpr, tpr, thresholds = roc_curve(Y_test, y_scores)

fpr

tpr

thresholds

#calculate ROC-AUC score and plot ROC curve#
from sklearn.metrics import roc_curve, auc
y_scores = logistic_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(Y_test, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()